{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "Analyze the provided IMDb datasets (\"https://developer.imdb.com/non-commercial-datasets/\") to uncover trends and insights related to how factors like genres, directors, actors, and runtime influence movie ratings and popularity. Address the exploratory questions provided, build an interactive visualization showing a director's top 3 movies by rating and runtime, and perform predictive and descriptive analysis, documenting the methodology and findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect data\n",
    "\n",
    "### Subtask:\n",
    "Load the relevant TSV files into pandas DataFrames and inspect their structure, including columns, data types, and missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reasoning**:\n",
    "Load the specified TSV files into pandas DataFrames and inspect their structure as instructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze runtime correlation\n",
    "### Subtask:\n",
    "Examine the correlation between movie length (runtime) and rating or popularity using 'title.basics.tsv.gz' and 'title.ratings.tsv.gz'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# IMDb Data Mining Project â€” Cleaned & Focused Visualization (Top 30K Rows)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load Datasets Safely with Row Limit\n",
    "def load_tsv(path, nrows=30000):\n",
    "    return pd.read_csv(path, sep='\\t', low_memory=False, na_values='\\\\N', nrows=nrows)\n",
    "\n",
    "title_basics_df = load_tsv('/content/title.basics.tsv.gz')\n",
    "title_ratings_df = load_tsv('/content/title.ratings.tsv.gz')\n",
    "\n",
    "print(\"Data Loaded (Top 30K rows from each dataset)\")\n",
    "print(f\"Title Basics shape: {title_basics_df.shape}\")\n",
    "print(f\"Title Ratings shape: {title_ratings_df.shape}\")\n",
    "\n",
    "# Step 2: Clean and Convert Datatypes\n",
    "title_basics_df['startYear'] = pd.to_numeric(title_basics_df['startYear'], errors='coerce')\n",
    "title_ratings_df['averageRating'] = pd.to_numeric(title_ratings_df['averageRating'], errors='coerce')\n",
    "title_ratings_df['numVotes'] = pd.to_numeric(title_ratings_df['numVotes'], errors='coerce')\n",
    "\n",
    "# Step 3: Merge title_basics and title_ratings\n",
    "merged_df = pd.merge(title_basics_df, title_ratings_df, on='tconst', how='inner')\n",
    "merged_df = merged_df.dropna(subset=['averageRating', 'numVotes', 'startYear'])\n",
    "merged_df = merged_df[merged_df['titleType'] == 'movie']\n",
    "\n",
    "print(f\"Merged DataFrame Shape (after filtering): {merged_df.shape}\")\n",
    "display(merged_df.head(3))\n",
    "\n",
    "# Step 4: Sampling for Visualization\n",
    "eda_sample = merged_df.sample(n=min(5000, len(merged_df)), random_state=42)\n",
    "\n",
    "# 1. Average IMDb Rating Trend Over the Years\n",
    "plt.figure(figsize=(10,6))\n",
    "yearly_ratings = merged_df.groupby('startYear')['averageRating'].mean().dropna()\n",
    "sns.lineplot(x=yearly_ratings.index, y=yearly_ratings.values, color='blue', marker='o')\n",
    "plt.title('Average IMDb Movie Rating Trend Over Years', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Release Year')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 2. Genre Popularity by Count\n",
    "if 'genres' in merged_df.columns:\n",
    "    genre_df = merged_df.dropna(subset=['genres'])\n",
    "    genre_df = genre_df.assign(genres=genre_df['genres'].str.split(',')).explode('genres')\n",
    "    top_genres = genre_df['genres'].value_counts().head(10)\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.barplot(x=top_genres.values, y=top_genres.index, palette='mako')\n",
    "    plt.title('Top 10 Most Common Movie Genres', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Number of Movies')\n",
    "    plt.ylabel('Genre')\n",
    "    plt.show()\n",
    "\n",
    "# 3. Ratings vs Votes (Popularity vs Quality)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x='numVotes', y='averageRating', data=eda_sample, alpha=0.5, color='green')\n",
    "plt.title('Movie Popularity vs Quality', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Number of Votes (log scale)')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.xscale('log')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClean Visualization Completed Successfully (No Clustering, High Impact Graphs)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the title.basics.tsv.gz and title.ratings.tsv.gz datasets into pandas DataFrames.\n",
    "title_basics_df = pd.read_csv('/content/title.basics.tsv.gz', sep='\\t', low_memory=False)\n",
    "title_ratings_df = pd.read_csv('/content/title.ratings.tsv.gz', sep='\\t')\n",
    "\n",
    "# 2. Filter the title_basics_df to include only 'movie' and 'tvMovie' title types.\n",
    "filtered_basics_df = title_basics_df[title_basics_df['titleType'].isin(['movie', 'tvMovie'])].copy()\n",
    "\n",
    "# 3. Handle the runtimeMinutes column in the filtered title_basics_df: replace '\\N' values with NaN and convert the column to a numeric type.\n",
    "filtered_basics_df['runtimeMinutes'] = filtered_basics_df['runtimeMinutes'].replace('\\\\N', np.nan)\n",
    "filtered_basics_df['runtimeMinutes'] = pd.to_numeric(filtered_basics_df['runtimeMinutes'], errors='coerce')\n",
    "\n",
    "# 4. Merge the filtered title_basics_df and title_ratings_df DataFrames on the 'tconst' column using an inner join.\n",
    "merged_df = pd.merge(filtered_basics_df, title_ratings_df, on='tconst', how='inner')\n",
    "\n",
    "# 5. Drop rows with missing values in the 'runtimeMinutes', 'averageRating', and 'numVotes' columns from the merged DataFrame.\n",
    "cleaned_merged_df = merged_df.dropna(subset=['runtimeMinutes', 'averageRating', 'numVotes']).copy()\n",
    "\n",
    "# 6. Calculate the correlation matrix between 'runtimeMinutes', 'averageRating', and 'numVotes'.\n",
    "correlation_matrix = cleaned_merged_df[['runtimeMinutes', 'averageRating', 'numVotes']].corr()\n",
    "\n",
    "# 7. Display the correlation matrix.\n",
    "print(\"Correlation matrix between runtimeMinutes, averageRating, and numVotes:\")\n",
    "display(correlation_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
