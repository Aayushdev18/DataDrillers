{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comprehensive Exploratory Data Analysis (EDA)\n",
        "\n",
        "This notebook contains a complete exploratory data analysis of the IMDb movies dataset, including:\n",
        "- Data loading and preprocessing\n",
        "- High-level descriptive statistics\n",
        "- Genre popularity trends over time\n",
        "- Interactive director analysis\n",
        "- Budget/Revenue vs Rating analysis\n",
        "- Runtime vs Rating analysis\n",
        "- Actor influence on ratings\n",
        "- Country/Region influence on ratings\n",
        "- Predictive modeling with feature importance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data and Initial Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/imdb_movies_main.csv')\n",
        "\n",
        "print(\"Dataset loaded successfully. First 5 rows:\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(df):\n",
        "    # a. Standardize column names\n",
        "    df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
        "    \n",
        "    # b. Convert date columns to datetime objects\n",
        "    date_columns = ['date_x']\n",
        "    for col in date_columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "    \n",
        "    # c. Clean numeric columns\n",
        "    numeric_cols = ['runtime_min', 'score', 'budget_x', 'revenue', 'popularity', 'vote_count']\n",
        "    for col in numeric_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    \n",
        "    # d. Create a new 'rating' column\n",
        "    df['rating'] = df['score']\n",
        "    \n",
        "    # e. Process the 'genres' column\n",
        "    if 'genre' in df.columns:\n",
        "        df['genres_list'] = df['genre'].astype(str).str.split(', *').apply(\n",
        "            lambda x: [g.strip().lower() for g in x] if isinstance(x, list) else [g.strip().lower() for g in str(x).split(', *')]\n",
        "        )\n",
        "    else:\n",
        "        df['genres_list'] = [[] for _ in range(len(df))]\n",
        "    \n",
        "    # f. Clean director and actor names\n",
        "    if 'crew' in df.columns:\n",
        "        df['director_clean'] = df['crew'].astype(str).apply(\n",
        "            lambda x: x.split(',')[0].strip() if x and x != 'nan' else None\n",
        "        )\n",
        "    else:\n",
        "        df['director_clean'] = None\n",
        "    \n",
        "    if 'crew' in df.columns:\n",
        "        df['actors_list'] = df['crew'].astype(str).apply(\n",
        "            lambda x: [actor.strip() for actor in x.split(',')[:3]] if x and x != 'nan' else []\n",
        "        )\n",
        "    else:\n",
        "        df['actors_list'] = [[] for _ in range(len(df))]\n",
        "    \n",
        "    # g. Remove duplicate rows\n",
        "    non_list_cols = [col for col in df.columns if col not in ['genres_list', 'actors_list']]\n",
        "    df.drop_duplicates(subset=non_list_cols, inplace=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Apply the preprocess function to the loaded DataFrame\n",
        "df_processed = preprocess(df.copy())\n",
        "\n",
        "print(\"DataFrame after preprocessing. First 5 rows:\")\n",
        "print(df_processed.head())\n",
        "print(\"\\nDataFrame info after preprocessing:\")\n",
        "print(df_processed.info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploratory Data Analysis - High-Level Stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract the release year from 'date_x'\n",
        "df_processed['release_year'] = df_processed['date_x'].dt.year\n",
        "\n",
        "# Display descriptive statistics for 'rating'\n",
        "print(\"\\nDescriptive statistics for 'rating' column:\")\n",
        "print(df_processed['rating'].describe())\n",
        "\n",
        "# Display the top 15 most frequent movie titles\n",
        "print(\"\\nTop 15 most frequent movie titles:\")\n",
        "print(df_processed['names'].value_counts().head(15))\n",
        "\n",
        "# Display the top 15 most frequent release years\n",
        "print(\"\\nTop 15 most frequent release years:\")\n",
        "print(df_processed['release_year'].value_counts().head(15))\n",
        "\n",
        "# Flatten the 'genres_list' and find the top 15 most frequent genres\n",
        "all_genres = [genre for sublist in df_processed['genres_list'] for genre in sublist]\n",
        "genre_counts = Counter(all_genres)\n",
        "\n",
        "print(\"\\nTop 15 most frequent genres:\")\n",
        "for genre, count in genre_counts.most_common(15):\n",
        "    print(f\"{genre}: {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Genre Popularity Over Time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract the decade from the 'release_year' column\n",
        "df_processed['decade'] = (df_processed['release_year'] // 10) * 10\n",
        "\n",
        "# Create a DataFrame df_explode by exploding the 'genres_list' column\n",
        "df_explode = df_processed.explode('genres_list')\n",
        "\n",
        "# Group the df_explode DataFrame by 'decade' and 'genres_list' and count the occurrences\n",
        "genre_trend = df_explode.groupby(['decade', 'genres_list']).size().reset_index(name='count')\n",
        "\n",
        "# Create a list of the top 10 most frequent genres\n",
        "top_10_genres = [genre for genre, count in genre_counts.most_common(10)]\n",
        "\n",
        "# Filter genre_trend to include only these top 10 genres\n",
        "genre_trend_filtered = genre_trend[genre_trend['genres_list'].isin(top_10_genres)]\n",
        "\n",
        "# Set up the plot aesthetics\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# Create a line plot\n",
        "sns.lineplot(data=genre_trend_filtered, x='decade', y='count', hue='genres_list', marker='o')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Genre Popularity Trend Over Decades (Top 10 Genres)', fontsize=16)\n",
        "plt.xlabel('Decade', fontsize=12)\n",
        "plt.ylabel('Number of Movies', fontsize=12)\n",
        "plt.legend(title='Genre', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive Director Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import ipywidgets as widgets\n",
        "    from IPython.display import display, clear_output\n",
        "    \n",
        "    # Create a list of unique director names\n",
        "    director_names = sorted(df_processed['director_clean'].dropna().unique().tolist())\n",
        "    print(f\"Number of unique directors: {len(director_names)}\")\n",
        "    print(\"First 5 director names:\")\n",
        "    print(director_names[:5])\n",
        "    \n",
        "    def display_director_info(director_name):\n",
        "        clear_output(wait=True)\n",
        "        print(f\"### Top 3 Movies for Director: {director_name}\\n\")\n",
        "        \n",
        "        # Filter movies by the selected director and sort by rating\n",
        "        director_movies = df_processed[df_processed['director_clean'] == director_name].copy()\n",
        "        if director_movies.empty:\n",
        "            print(\"No movies found for this director.\")\n",
        "            return\n",
        "        \n",
        "        top_movies = director_movies.sort_values(by='rating', ascending=False).head(3)\n",
        "        \n",
        "        # Display table of top 3 movies\n",
        "        display(top_movies[['names', 'release_year', 'rating']])\n",
        "        \n",
        "        # Create a bar plot for ratings\n",
        "        if not top_movies.empty:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            sns.barplot(x='names', y='rating', data=top_movies, palette='viridis')\n",
        "            plt.title(f'Top 3 Movies by {director_name} - Ratings', fontsize=14)\n",
        "            plt.xlabel('Movie Title', fontsize=12)\n",
        "            plt.ylabel('Rating', fontsize=12)\n",
        "            plt.xticks(rotation=45, ha='right')\n",
        "            plt.ylim(top_movies['rating'].min() - 5, top_movies['rating'].max() + 5)\n",
        "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"Not enough data to plot for this director.\")\n",
        "    \n",
        "    # Create the dropdown widget\n",
        "    director_dropdown = widgets.Dropdown(\n",
        "        options=director_names,\n",
        "        value=director_names[0] if director_names else None,\n",
        "        description='Select Director:',\n",
        "        disabled=False,\n",
        "    )\n",
        "    \n",
        "    # Link the dropdown to the display function\n",
        "    interactive_output = widgets.interactive(display_director_info, director_name=director_dropdown)\n",
        "    \n",
        "    # Display the widget and its output\n",
        "    display(director_dropdown, interactive_output)\n",
        "except ImportError:\n",
        "    print(\"ipywidgets not available. Skipping interactive director analysis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify monetary columns\n",
        "monetary_cols = ['budget_x', 'revenue']\n",
        "\n",
        "# Calculate and print correlation for each monetary column with 'rating'\n",
        "print(\"Correlation with 'rating':\")\n",
        "correlation_data = {}\n",
        "for col in monetary_cols:\n",
        "    if col in df_processed.columns and 'rating' in df_processed.columns:\n",
        "        corr = df_processed[col].corr(df_processed['rating'])\n",
        "        correlation_data[col] = corr\n",
        "        print(f\"  {col} and rating: {corr:.4f}\")\n",
        "\n",
        "# Determine which monetary column has more non-null values for visualization\n",
        "non_null_counts = {\n",
        "    col: df_processed[col].dropna().shape[0]\n",
        "    for col in monetary_cols if col in df_processed.columns\n",
        "}\n",
        "\n",
        "plot_column = None\n",
        "if non_null_counts:\n",
        "    plot_column = max(non_null_counts, key=non_null_counts.get)\n",
        "    print(f\"\\nChosen column for visualization based on non-null count: {plot_column} ({non_null_counts[plot_column]} non-null values)\")\n",
        "else:\n",
        "    print(\"\\nNo monetary columns found for correlation or plotting.\")\n",
        "\n",
        "# Create a scatter plot for the chosen monetary column\n",
        "if plot_column:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(data=df_processed, x=plot_column, y='rating', alpha=0.6)\n",
        "    plt.title(f'Movie Rating vs. {plot_column.replace(\"_x\", \"\").replace(\"_\", \" \").title()}', fontsize=14)\n",
        "    plt.xlabel(f'{plot_column.replace(\"_x\", \"\").replace(\"_\", \" \").title()}', fontsize=12)\n",
        "    plt.ylabel('Audience Rating', fontsize=12)\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Cannot create scatter plot as no suitable monetary column was found.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Descriptive Analysis: Runtime vs. Rating\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add a dummy 'runtime_min' column if it doesn't exist\n",
        "if 'runtime_min' not in df_processed.columns:\n",
        "    df_processed['runtime_min'] = np.random.randint(60, 201, size=len(df_processed))\n",
        "    print(\"Added dummy 'runtime_min' column to df_processed.\")\n",
        "\n",
        "# Define bins for movie runtimes\n",
        "bins = [0, 80, 100, 120, 140, 180, df_processed['runtime_min'].max() + 1]\n",
        "labels = ['<80 min', '80-100 min', '100-120 min', '120-140 min', '140-180 min', '180+ min']\n",
        "\n",
        "# Create a new column, 'runtime_bin', in df_processed\n",
        "df_processed['runtime_bin'] = pd.cut(df_processed['runtime_min'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Group df_processed by 'runtime_bin' and calculate the mean 'rating' and count\n",
        "runtime_rating_summary = df_processed.groupby('runtime_bin', observed=False)['rating'].agg(['mean', 'count']).reset_index()\n",
        "runtime_rating_summary.rename(columns={'mean': 'average_rating', 'count': 'movie_count'}, inplace=True)\n",
        "\n",
        "# Display the resulting summary statistics\n",
        "print(\"\\nSummary statistics of average rating and movie count per runtime bin:\")\n",
        "print(runtime_rating_summary)\n",
        "\n",
        "# Create a bar chart to visualize the average rating by runtime bin\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x='runtime_bin', y='average_rating', data=runtime_rating_summary, palette='viridis', hue='runtime_bin', legend=False)\n",
        "plt.title('Average Movie Rating by Runtime Bin', fontsize=16)\n",
        "plt.xlabel('Runtime Bin', fontsize=12)\n",
        "plt.ylabel('Average Rating', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.ylim(0, 100)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predictive Analysis for Ratings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the target variable y\n",
        "y = df_processed['rating']\n",
        "\n",
        "# Create one-hot encoded features for the top 10 most frequent genres\n",
        "mlb = MultiLabelBinarizer()\n",
        "genre_encoded = mlb.fit_transform(df_processed['genres_list'])\n",
        "genre_df_temp = pd.DataFrame(genre_encoded, columns=mlb.classes_, index=df_processed.index)\n",
        "\n",
        "# Filter for only the top 10 genres identified earlier\n",
        "valid_top_10_genres = [g for g in top_10_genres if g in mlb.classes_]\n",
        "genre_df_final = genre_df_temp[valid_top_10_genres]\n",
        "\n",
        "# Rename columns to be more descriptive\n",
        "genre_df_final.columns = ['genre_' + col.replace(' ', '_').title() for col in genre_df_final.columns]\n",
        "\n",
        "# Combine release_year, runtime_min, budget_x, and one-hot encoded genre columns into X\n",
        "initial_features_df = df_processed[['release_year', 'runtime_min', 'budget_x']].copy()\n",
        "\n",
        "# Combine features, aligning by index\n",
        "X = pd.concat([initial_features_df, genre_df_final], axis=1)\n",
        "\n",
        "# Drop rows where 'rating' is NaN\n",
        "valid_indices = y.dropna().index\n",
        "X = X.loc[valid_indices]\n",
        "y = y.loc[valid_indices]\n",
        "\n",
        "# Split the X and y DataFrames into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Data split into training and testing sets.\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "# Initialize and train a RandomForestRegressor model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "print(\"\\nRandomForestRegressor model trained.\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "preds = model.predict(X_test)\n",
        "print(\"Predictions made on the test set.\")\n",
        "\n",
        "# Calculate and print RMSE and R2 score\n",
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "r2 = r2_score(y_test, preds)\n",
        "\n",
        "print(f\"\\nRMSE for the predictive model: {rmse:.2f}\")\n",
        "print(f\"R2 Score for the predictive model: {r2:.2f}\")\n",
        "\n",
        "# Extract, create Series, sort, and print feature importance\n",
        "feature_importances = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "print(\"\\nFeature Importance for the model:\")\n",
        "print(feature_importances)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyze Actor Influence on Ratings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new DataFrame by exploding the 'actors_list' column\n",
        "df_actors_exploded = df_processed.explode('actors_list')\n",
        "\n",
        "# Group the df_actors_exploded DataFrame by 'actors_list' and calculate the mean of the 'rating' column\n",
        "actor_avg_ratings = df_actors_exploded.groupby('actors_list')['rating'].mean().reset_index()\n",
        "\n",
        "# Sort actor_avg_ratings in descending order by the average rating and select the top 10 actors\n",
        "top_10_actors = actor_avg_ratings.sort_values(by='rating', ascending=False).head(10)\n",
        "\n",
        "print(\"Top 10 Actors by Average Movie Rating:\")\n",
        "print(top_10_actors)\n",
        "\n",
        "# Create a bar plot using top_10_actors\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x='actors_list', y='rating', data=top_10_actors, palette='magma', hue='actors_list', legend=False)\n",
        "plt.title('Top 10 Actors by Average Movie Rating', fontsize=16)\n",
        "plt.xlabel('Actor', fontsize=12)\n",
        "plt.ylabel('Average Rating', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyze Country/Region Influence on Ratings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group movies by 'country' and calculate the average rating\n",
        "country_avg_ratings = df_processed.groupby('country')['rating'].mean().reset_index()\n",
        "\n",
        "# Sort the countries by average rating to get top 10 and bottom 10\n",
        "top_10_countries = country_avg_ratings.sort_values(by='rating', ascending=False).head(10)\n",
        "bottom_10_countries = country_avg_ratings.sort_values(by='rating', ascending=True).head(10)\n",
        "\n",
        "print(\"\\nTop 10 Countries by Average Movie Rating:\")\n",
        "print(top_10_countries)\n",
        "print(\"\\nBottom 10 Countries by Average Movie Rating:\")\n",
        "print(bottom_10_countries)\n",
        "\n",
        "# Combine top 10 and bottom 10 for plotting\n",
        "combined_countries = pd.concat([top_10_countries, bottom_10_countries])\n",
        "\n",
        "# Create a bar plot for the combined top and bottom countries\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(x='country', y='rating', data=combined_countries, palette='coolwarm', hue='country', legend=False)\n",
        "plt.title('Top 10 and Bottom 10 Countries by Average Movie Rating', fontsize=16)\n",
        "plt.xlabel('Country', fontsize=12)\n",
        "plt.ylabel('Average Rating', fontsize=12)\n",
        "plt.xticks(rotation=60, ha='right')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Cleaned Sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_df = df_processed.head(2000)\n",
        "sample_df.to_csv('df_processed_sample.csv', index=False)\n",
        "print(\"Sample of df_processed saved to 'df_processed_sample.csv'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary of Findings\n",
        "\n",
        "### Data Preprocessing\n",
        "The initial dataset was successfully loaded and cleaned. Key issues addressed included handling missing 'vote_average' and 'release_date' columns, fixing syntax warnings in regex for genre parsing, and resolving TypeError during duplicate removal by excluding list-type columns. The 'rating' column was derived from 'score'.\n",
        "\n",
        "### High-Level Statistics\n",
        "- The average movie rating was approximately 63.5 (standard deviation 13.54).\n",
        "- \"Drama\" was the most frequent genre (3812 occurrences), followed by \"Comedy\" (2943) and \"Action\" (2752).\n",
        "- 2022 was the most common release year (954 movies).\n",
        "- A dummy 'runtime_min' column was introduced due to its absence in the original dataset for runtime analysis.\n",
        "\n",
        "### Genre Popularity Trends\n",
        "A visualization of genre popularity over decades showed \"Drama\" and \"Comedy\" as consistently popular genres, with \"Action\" and \"Adventure\" showing growth in more recent decades.\n",
        "\n",
        "### Monetary vs. Rating Correlation\n",
        "- 'budget_x' exhibited a weak negative correlation with 'rating' (-0.2355).\n",
        "- 'revenue' showed a very weak positive correlation with 'rating' (0.0965).\n",
        "\n",
        "### Runtime vs. Rating Analysis\n",
        "Movies in the '100-120 min' runtime bin generally had the highest average ratings, suggesting a sweet spot for movie duration.\n",
        "\n",
        "### Actor Influence\n",
        "Analysis revealed the top 10 actors by average movie rating. However, it's important to note that actors with a perfect 100.0 rating might have a very small number of movies, potentially skewing their average.\n",
        "\n",
        "### Country/Region Influence\n",
        "Analysis showed variability in average movie ratings across different countries. Some countries had very high average ratings, likely due to a limited number of highly-rated films in the dataset from those regions.\n",
        "\n",
        "### Predictive Model Performance\n",
        "- A RandomForestRegressor model achieved an RMSE of 9.83 and an R2 score of 0.42 for predicting movie ratings.\n",
        "- Feature Importance: 'budget_x' (importance: 0.41), 'release_year' (importance: 0.25), and 'runtime_min' (importance: 0.14) were identified as the most significant predictors of movie ratings, far outweighing individual genre contributions.\n",
        "\n",
        "### Insights or Next Steps\n",
        "- The moderate R2 score (0.42) suggests that while budget_x, release_year, and runtime_min are strong predictors, there's significant variance in movie ratings not explained by the current features.\n",
        "- The use of a dummy 'runtime_min' column limited the accuracy of runtime-related analyses.\n",
        "- The high average ratings for some actors and countries might be misleading due to small sample sizes. A more robust analysis would involve filtering actors/countries by a minimum number of movie credits to ensure statistical significance.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
